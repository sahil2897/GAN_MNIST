{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MhPdmtpxfkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Reshape, Dense, Conv2D, Conv2DTranspose, LeakyReLU, Dropout, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets.mnist import load_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAscHLtEzhrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIBupstF9yrJ",
        "colab_type": "text"
      },
      "source": [
        "# DISCRIMINATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzg3DXB979dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPNnyBX8945M",
        "colab_type": "text"
      },
      "source": [
        "# GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKDQmcWF9RjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TETiwXXf9-cy",
        "colab_type": "text"
      },
      "source": [
        "# GAN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as0KglpU9TjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "\td_model.trainable = False\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(g_model)\n",
        "\tmodel.add(d_model)\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aroRB7pV9WQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_real_samples():\n",
        "\t(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\tX = expand_dims(x_train, axis=-1)\n",
        "\tX = X.astype('float32')\n",
        "\tX = X / 255.0\n",
        "\treturn X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q4UGYLG9afc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\tX = dataset[ix]\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEXBLuYV9cN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\tX = g_model.predict(x_input)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNOCL1N6BcfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz0G2qBE9eXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_plot(examples, epoch, n=10):\n",
        "\tfor i in range(n * n):\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(examples[i, :, :, 0], cmap='gray')\n",
        "\tfilename = 'generated_plot_{}.png'.format(epoch+1)\n",
        "\tplt.savefig(filename)\n",
        "\tplt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJywfwLZ9ulI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\tloss_real, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\tloss_fake, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\tprint('Accuracy real: {}, fake: {}' .format(acc_real*100, acc_fake*100))\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\tfilename = 'generator_model_{}.h5'.format(epoch + 1)\n",
        "\tg_model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxmzH_8l9gRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
        "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "  half_batch = int(n_batch / 2)\n",
        "  for i in range(n_epochs):\n",
        "    for j in range(bat_per_epo):\n",
        "      X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "      X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
        "      d_loss, _ = d_model.train_on_batch(X, y)\n",
        "      X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "      y_gan = ones((n_batch, 1))\n",
        "      g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "    print('epoch: {}, iteration: {}/{}, d_loss={}, g_loss={}'.format(i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "    if (i+1) % 10 == 0:\n",
        "      summarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPKccTx29mdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d06e364-260c-45bd-cd79-8981a04fe0ec"
      },
      "source": [
        "d_model = define_discriminator()\n",
        "g_model = define_generator(latent_dim)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "dataset = load_real_samples()\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, iteration: 234/234, d_loss=0.7042316198348999, g_loss=0.9015730023384094\n",
            "epoch: 2, iteration: 234/234, d_loss=0.6630631685256958, g_loss=0.7506245970726013\n",
            "epoch: 3, iteration: 234/234, d_loss=0.7120928168296814, g_loss=0.7137573957443237\n",
            "epoch: 4, iteration: 234/234, d_loss=0.6842965483665466, g_loss=0.6915127038955688\n",
            "epoch: 5, iteration: 234/234, d_loss=0.669113039970398, g_loss=0.734778881072998\n",
            "epoch: 6, iteration: 234/234, d_loss=0.7073245048522949, g_loss=0.6882988810539246\n",
            "epoch: 7, iteration: 234/234, d_loss=0.6959494948387146, g_loss=0.7014248967170715\n",
            "epoch: 8, iteration: 234/234, d_loss=0.702278196811676, g_loss=0.7019523978233337\n",
            "epoch: 9, iteration: 234/234, d_loss=0.6963443756103516, g_loss=0.7139756679534912\n",
            "epoch: 10, iteration: 234/234, d_loss=0.6852003335952759, g_loss=0.7110025882720947\n",
            "Accuracy real: 56.00000000000001, fake: 48.0\n",
            "epoch: 11, iteration: 234/234, d_loss=0.690729022026062, g_loss=0.678305447101593\n",
            "epoch: 12, iteration: 234/234, d_loss=0.6844431161880493, g_loss=0.7343258261680603\n",
            "epoch: 13, iteration: 234/234, d_loss=0.6810287237167358, g_loss=0.7269711494445801\n",
            "epoch: 14, iteration: 234/234, d_loss=0.6917566061019897, g_loss=0.7025532722473145\n",
            "epoch: 15, iteration: 234/234, d_loss=0.68760746717453, g_loss=0.7317572236061096\n",
            "epoch: 16, iteration: 234/234, d_loss=0.6939586997032166, g_loss=0.7041292190551758\n",
            "epoch: 17, iteration: 234/234, d_loss=0.6921049356460571, g_loss=0.6829400658607483\n",
            "epoch: 18, iteration: 234/234, d_loss=0.6924595236778259, g_loss=0.7256462574005127\n",
            "epoch: 19, iteration: 234/234, d_loss=0.6793391704559326, g_loss=0.6638510227203369\n",
            "epoch: 20, iteration: 234/234, d_loss=0.6935557126998901, g_loss=0.7112745046615601\n",
            "Accuracy real: 51.0, fake: 82.0\n",
            "epoch: 21, iteration: 234/234, d_loss=0.6807068586349487, g_loss=0.6781700849533081\n",
            "epoch: 22, iteration: 234/234, d_loss=0.6857304573059082, g_loss=0.7100095748901367\n",
            "epoch: 23, iteration: 234/234, d_loss=0.6736438274383545, g_loss=0.7225634455680847\n",
            "epoch: 24, iteration: 234/234, d_loss=0.6958174109458923, g_loss=0.6681944131851196\n",
            "epoch: 25, iteration: 234/234, d_loss=0.6902052760124207, g_loss=0.7138659954071045\n",
            "epoch: 26, iteration: 234/234, d_loss=0.6862313747406006, g_loss=0.7051211595535278\n",
            "epoch: 27, iteration: 234/234, d_loss=0.6863387823104858, g_loss=0.773352861404419\n",
            "epoch: 28, iteration: 234/234, d_loss=0.688650369644165, g_loss=0.7133322358131409\n",
            "epoch: 29, iteration: 234/234, d_loss=0.6891718506813049, g_loss=0.6991314888000488\n",
            "epoch: 30, iteration: 234/234, d_loss=0.685729444026947, g_loss=0.6978392601013184\n",
            "Accuracy real: 63.0, fake: 63.0\n",
            "epoch: 31, iteration: 234/234, d_loss=0.6842487454414368, g_loss=0.6871201992034912\n",
            "epoch: 32, iteration: 234/234, d_loss=0.6854444742202759, g_loss=0.7617427110671997\n",
            "epoch: 33, iteration: 234/234, d_loss=0.6859453916549683, g_loss=0.7152754068374634\n",
            "epoch: 34, iteration: 234/234, d_loss=0.6874831914901733, g_loss=0.7153929471969604\n",
            "epoch: 35, iteration: 234/234, d_loss=0.683030366897583, g_loss=0.7046003341674805\n",
            "epoch: 36, iteration: 234/234, d_loss=0.6951431035995483, g_loss=0.6886240243911743\n",
            "epoch: 37, iteration: 234/234, d_loss=0.6937028169631958, g_loss=0.726548433303833\n",
            "epoch: 38, iteration: 234/234, d_loss=0.6832149028778076, g_loss=0.7390150427818298\n",
            "epoch: 39, iteration: 234/234, d_loss=0.6914676427841187, g_loss=0.7178439497947693\n",
            "epoch: 40, iteration: 234/234, d_loss=0.6987859606742859, g_loss=0.6822904348373413\n",
            "Accuracy real: 94.0, fake: 30.0\n",
            "epoch: 41, iteration: 234/234, d_loss=0.6823863983154297, g_loss=0.6715237498283386\n",
            "epoch: 42, iteration: 234/234, d_loss=0.6753551959991455, g_loss=0.7064170837402344\n",
            "epoch: 43, iteration: 234/234, d_loss=0.6938133239746094, g_loss=0.7018639445304871\n",
            "epoch: 44, iteration: 234/234, d_loss=0.6894607543945312, g_loss=0.70939040184021\n",
            "epoch: 45, iteration: 234/234, d_loss=0.688101053237915, g_loss=0.6775675415992737\n",
            "epoch: 46, iteration: 234/234, d_loss=0.684792160987854, g_loss=0.708713710308075\n",
            "epoch: 47, iteration: 234/234, d_loss=0.6857092976570129, g_loss=0.7040899991989136\n",
            "epoch: 48, iteration: 234/234, d_loss=0.6871484518051147, g_loss=0.7214065194129944\n",
            "epoch: 49, iteration: 234/234, d_loss=0.6903542876243591, g_loss=0.7211567163467407\n",
            "epoch: 50, iteration: 234/234, d_loss=0.6876078844070435, g_loss=0.7549420595169067\n",
            "Accuracy real: 8.0, fake: 99.0\n",
            "epoch: 51, iteration: 234/234, d_loss=0.6855414509773254, g_loss=0.6999111175537109\n",
            "epoch: 52, iteration: 234/234, d_loss=0.6900629997253418, g_loss=0.7027629017829895\n",
            "epoch: 53, iteration: 234/234, d_loss=0.7003140449523926, g_loss=0.6968838572502136\n",
            "epoch: 54, iteration: 234/234, d_loss=0.6904868483543396, g_loss=0.697789192199707\n",
            "epoch: 55, iteration: 234/234, d_loss=0.6930596232414246, g_loss=0.7018234729766846\n",
            "epoch: 56, iteration: 234/234, d_loss=0.6842934489250183, g_loss=0.6845278739929199\n",
            "epoch: 57, iteration: 234/234, d_loss=0.6863340735435486, g_loss=0.7212148308753967\n",
            "epoch: 58, iteration: 234/234, d_loss=0.6827892065048218, g_loss=0.7235506772994995\n",
            "epoch: 59, iteration: 234/234, d_loss=0.6865598559379578, g_loss=0.7230592966079712\n",
            "epoch: 60, iteration: 234/234, d_loss=0.6911033391952515, g_loss=0.7051727771759033\n",
            "Accuracy real: 41.0, fake: 76.0\n",
            "epoch: 61, iteration: 234/234, d_loss=0.6863936185836792, g_loss=0.713657557964325\n",
            "epoch: 62, iteration: 234/234, d_loss=0.6904863119125366, g_loss=0.6837841272354126\n",
            "epoch: 63, iteration: 234/234, d_loss=0.6909619569778442, g_loss=0.7012844085693359\n",
            "epoch: 64, iteration: 234/234, d_loss=0.6885508894920349, g_loss=0.7186146378517151\n",
            "epoch: 65, iteration: 234/234, d_loss=0.6925191879272461, g_loss=0.7164235711097717\n",
            "epoch: 66, iteration: 234/234, d_loss=0.6898723840713501, g_loss=0.7019056081771851\n",
            "epoch: 67, iteration: 234/234, d_loss=0.6958980560302734, g_loss=0.705083429813385\n",
            "epoch: 68, iteration: 234/234, d_loss=0.6908504366874695, g_loss=0.6967358589172363\n",
            "epoch: 69, iteration: 234/234, d_loss=0.6910099983215332, g_loss=0.6930028200149536\n",
            "epoch: 70, iteration: 234/234, d_loss=0.6811342835426331, g_loss=0.7060810923576355\n",
            "Accuracy real: 27.0, fake: 92.0\n",
            "epoch: 71, iteration: 234/234, d_loss=0.6910670399665833, g_loss=0.7049388289451599\n",
            "epoch: 72, iteration: 234/234, d_loss=0.6861721873283386, g_loss=0.6751124858856201\n",
            "epoch: 73, iteration: 234/234, d_loss=0.69674152135849, g_loss=0.7094407081604004\n",
            "epoch: 74, iteration: 234/234, d_loss=0.6929065585136414, g_loss=0.7161185145378113\n",
            "epoch: 75, iteration: 234/234, d_loss=0.6920111179351807, g_loss=0.6931234002113342\n",
            "epoch: 76, iteration: 234/234, d_loss=0.6875567436218262, g_loss=0.7000089883804321\n",
            "epoch: 77, iteration: 234/234, d_loss=0.6890131235122681, g_loss=0.6860957145690918\n",
            "epoch: 78, iteration: 234/234, d_loss=0.6885251998901367, g_loss=0.7091825604438782\n",
            "epoch: 79, iteration: 234/234, d_loss=0.6883149147033691, g_loss=0.6971991658210754\n",
            "epoch: 80, iteration: 234/234, d_loss=0.6879624128341675, g_loss=0.6962637901306152\n",
            "Accuracy real: 38.0, fake: 84.0\n",
            "epoch: 81, iteration: 234/234, d_loss=0.688720166683197, g_loss=0.7018055319786072\n",
            "epoch: 82, iteration: 234/234, d_loss=0.6898618936538696, g_loss=0.6777619123458862\n",
            "epoch: 83, iteration: 234/234, d_loss=0.6903669834136963, g_loss=0.6885141730308533\n",
            "epoch: 84, iteration: 234/234, d_loss=0.6923280954360962, g_loss=0.7172320485115051\n",
            "epoch: 85, iteration: 234/234, d_loss=0.6953297853469849, g_loss=0.6974813938140869\n",
            "epoch: 86, iteration: 234/234, d_loss=0.6911736726760864, g_loss=0.6848388910293579\n",
            "epoch: 87, iteration: 234/234, d_loss=0.6937951445579529, g_loss=0.6988414525985718\n",
            "epoch: 88, iteration: 234/234, d_loss=0.6933927536010742, g_loss=0.6985983848571777\n",
            "epoch: 89, iteration: 234/234, d_loss=0.6833605170249939, g_loss=0.6860316395759583\n",
            "epoch: 90, iteration: 234/234, d_loss=0.6903887391090393, g_loss=0.6986098289489746\n",
            "Accuracy real: 20.0, fake: 93.0\n",
            "epoch: 91, iteration: 234/234, d_loss=0.6865221261978149, g_loss=0.6972790360450745\n",
            "epoch: 92, iteration: 234/234, d_loss=0.6882667541503906, g_loss=0.7049365043640137\n",
            "epoch: 93, iteration: 234/234, d_loss=0.6951482892036438, g_loss=0.6878335475921631\n",
            "epoch: 94, iteration: 234/234, d_loss=0.6898945569992065, g_loss=0.7092708349227905\n",
            "epoch: 95, iteration: 234/234, d_loss=0.6957942247390747, g_loss=0.7047820687294006\n",
            "epoch: 96, iteration: 234/234, d_loss=0.688844621181488, g_loss=0.7083076238632202\n",
            "epoch: 97, iteration: 234/234, d_loss=0.691664457321167, g_loss=0.6897397637367249\n",
            "epoch: 98, iteration: 234/234, d_loss=0.6949949264526367, g_loss=0.6989237666130066\n",
            "epoch: 99, iteration: 234/234, d_loss=0.6848583221435547, g_loss=0.6884344816207886\n",
            "epoch: 100, iteration: 234/234, d_loss=0.6868783831596375, g_loss=0.7122381925582886\n",
            "Accuracy real: 5.0, fake: 99.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xt4BNcsY-gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}